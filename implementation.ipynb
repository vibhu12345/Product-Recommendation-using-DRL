{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#installations needed if not installed already\n",
        "!pip install pandas spacy numpy gym tensorflow matplotlib urllib3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkDNw2oQuOdl",
        "outputId": "f5563f54-d66e-4be2-c1ce-e4a3d7752070"
      },
      "id": "tkDNw2oQuOdl",
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "d297ad8c",
      "metadata": {
        "id": "d297ad8c"
      },
      "outputs": [],
      "source": [
        "#import statements\n",
        "import json\n",
        "import pandas as pd\n",
        "import spacy\n",
        "import numpy as np\n",
        "import gym\n",
        "import tensorflow as tf\n",
        "import copy\n",
        "import random\n",
        "import pylab\n",
        "import os\n",
        "import gzip\n",
        "from urllib.request import urlopen\n",
        "from collections import deque\n",
        "from keras import layers, models\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/AMAZON_FASHION.json.gz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5YwkfYuk6z6",
        "outputId": "26f872d0-bd51-46a4-a326-fcd31bbd4ab3"
      },
      "id": "d5YwkfYuk6z6",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-03 15:10:13--  https://datarepo.eng.ucsd.edu/mcauley_group/data/amazon_v2/categoryFiles/AMAZON_FASHION.json.gz\n",
            "Resolving datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)... 132.239.8.30\n",
            "Connecting to datarepo.eng.ucsd.edu (datarepo.eng.ucsd.edu)|132.239.8.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 93185167 (89M) [application/x-gzip]\n",
            "Saving to: ‘AMAZON_FASHION.json.gz’\n",
            "\n",
            "AMAZON_FASHION.json 100%[===================>]  88.87M  40.9MB/s    in 2.2s    \n",
            "\n",
            "2023-10-03 15:10:16 (40.9 MB/s) - ‘AMAZON_FASHION.json.gz’ saved [93185167/93185167]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###  Load JSON data\n",
        "\n",
        "data = []\n",
        "with gzip.open('AMAZON_FASHION.json.gz') as f:\n",
        "    for l in f:\n",
        "        data.append(json.loads(l.strip()))\n",
        "\n",
        "# total length of list, this number equals total number of products\n",
        "print(len(data))\n",
        "\n",
        "# first row of the list\n",
        "print(data[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiPfzapZlhf-",
        "outputId": "8193bf9b-0e98-4a4f-898c-f9c5efd67fd7"
      },
      "id": "KiPfzapZlhf-",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "883636\n",
            "{'overall': 5.0, 'verified': True, 'reviewTime': '10 20, 2014', 'reviewerID': 'A1D4G1SNUZWQOT', 'asin': '7106116521', 'reviewerName': 'Tracy', 'reviewText': 'Exactly what I needed.', 'summary': 'perfect replacements!!', 'unixReviewTime': 1413763200}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "53a24c3e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53a24c3e",
        "outputId": "2f0aceeb-f527-4a8c-acc7-8efdffe300af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    overall  verified      reviewerID        asin                 style  \\\n",
            "0       5.0      True  A1D4G1SNUZWQOT  7106116521                   NaN   \n",
            "1       2.0      True  A3DDWDH9PX2YX2  7106116521                   NaN   \n",
            "3       2.0      True  A2UH2QQ275NV45  7106116521                   NaN   \n",
            "5       5.0      True  A29HLOUW0NS0EH  7106116521                   NaN   \n",
            "6       4.0      True   A7QS961ROI6E0  7106116521                   NaN   \n",
            "7       3.0      True  A1BB77SEBQT8VX  B00007GDFV  {'Color:': ' Black'}   \n",
            "8       3.0      True   AHWOW7D1ABO9C  B00007GDFV  {'Color:': ' Black'}   \n",
            "9       3.0      True   AKS3GULZE0HFC  B00007GDFV  {'Color:': ' Black'}   \n",
            "10      4.0      True   A38NS6NF6WPXS  B00007GDFV  {'Color:': ' Black'}   \n",
            "11      2.0      True  A1KOKO3HTSAI1H  B00007GDFV  {'Color:': ' Black'}   \n",
            "\n",
            "          reviewerName                                         reviewText  \\\n",
            "0                Tracy                             Exactly what I needed.   \n",
            "1            Sonja Lau  I agree with the other review, the opening is ...   \n",
            "3          Jodi Stoner                                too tiny an opening   \n",
            "5    Patricia R. Erwin                             Exactly what I wanted.   \n",
            "6     REBECCA S LAYTON  These little plastic backs work great.  No mor...   \n",
            "7   Darrow H Ankrum II  mother - in - law wanted it as a present for h...   \n",
            "8               rosieO  Item is of good quality. Looks great, too. But...   \n",
            "9           M. Waltman  I had used my last el-cheapo fake leather ciga...   \n",
            "10            BTDoxies  This brand has been around a long time and you...   \n",
            "11        Robin Howard  I smoke 100's and these are NOT made for them....   \n",
            "\n",
            "                                              summary   reviewTime  \n",
            "0                              perfect replacements!!  10 20, 2014  \n",
            "1   I agree with the other review, the opening is ...  09 28, 2014  \n",
            "3                                           Two Stars  08 24, 2014  \n",
            "5                                          Five Stars  07 19, 2014  \n",
            "6                                        Works great!  05 31, 2014  \n",
            "7                                 bought as a present  09 22, 2013  \n",
            "8                           Buxton heiress collection  07 17, 2013  \n",
            "9                      Top Clasp Broke Within 3 days!  04 13, 2013  \n",
            "10                                    BUXTON QUALITY!   03 9, 2013  \n",
            "11  Buxton Heiress Collection Black Leather Cigare...  01 27, 2013  \n"
          ]
        }
      ],
      "source": [
        "#load spacy for nlp related noun extraction, stopword removal and others\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "# Create a DataFrame for easier data manipulation\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "df = df[['overall','verified','reviewerID','asin','style','reviewerName','reviewText', 'summary','reviewTime']]\n",
        "\n",
        "# Filter verified reviews with non-null overall ratings\n",
        "filtered_df = df[(df['verified'] == True) & (~df['overall'].isnull())]\n",
        "\n",
        "print(filtered_df.head(10))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Create FashionProduct class for a product representation from reviews\n",
        "class FashionProduct() : pass\n",
        "class Reviewer() : pass\n",
        "# extract nouns from review text\n",
        "def extract_nouns(doc):\n",
        "    return \" \".join([token.text for token in doc if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "483aea42",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "483aea42",
        "outputId": "bbb21cdf-4e9d-4776-a8e1-ea01de2089e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110\n"
          ]
        }
      ],
      "source": [
        "# group reviews by reviewers\n",
        "reviewers= {}\n",
        "class Reviewer() : pass\n",
        "grouped_df_reviwerId = filtered_df.groupby('reviewerID')\n",
        "for reviewerId, group in grouped_df_reviwerId:\n",
        "    products= group[group['asin'].notna()]['asin'].unique()\n",
        "    if len(products)>10:\n",
        "        reviewer= Reviewer()\n",
        "        reviewer.reviewerId = reviewerId\n",
        "        reviewer.products = products\n",
        "        reviewer.product_cnt = len(products)\n",
        "        reviewers[reviewerId]= reviewer\n",
        "print(len(reviewers))\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "35aac91b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35aac91b",
        "outputId": "8ef5ba88-2c64-48c6-acd8-f1b810dc6d03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12\n",
            "35\n"
          ]
        }
      ],
      "source": [
        "reviewer_values= list(reviewers.values())\n",
        "print (len([reviewer for reviewer in reviewer_values if reviewer.product_cnt>=20]))\n",
        "print (len([reviewer for reviewer in reviewer_values if reviewer.product_cnt>=15]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e67ff39a",
      "metadata": {
        "id": "e67ff39a"
      },
      "source": [
        "### Hence we do not have decent no. of users who have purchases more than 15 or 20 products, so we will go with reviewers who have purchased more than 10 products only. We will filter out reviewers with less than or equal to 10 products and go with recommending only two products per product for better accuracy in prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "da1ed3fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da1ed3fd",
        "outputId": "55549710-bcca-41c1-e720-7310c6e4bbac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "828699\n",
            "1622\n"
          ]
        }
      ],
      "source": [
        "print(len(filtered_df))\n",
        "#remove other reviewer's data\n",
        "filtered_df = filtered_df[(filtered_df['reviewerID'].isin([reviewer.reviewerId for reviewer in reviewer_values]) )]\n",
        "print(len(filtered_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "547603f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "547603f2",
        "outputId": "d887d225-e2be-4e04-b338-8afe82c1d616"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       overall  verified      reviewerID        asin  \\\n",
            "3368       5.0      True   AAC2BU2V9X95K  B000EE1NNA   \n",
            "12731      5.0      True  A1H2WJSALF3E9U  B000KPIHQ4   \n",
            "16417      5.0      True  A2IQT5AFFXA1OM  B000NBIMG0   \n",
            "17435      5.0      True  A2T2ZJ8NQ7PP5J  B000NGJ41W   \n",
            "26234      5.0      True  A1H2WJSALF3E9U  B000V0IBDM   \n",
            "33572      5.0      True  A3BX45SC5SG8BM  B0014F8TIU   \n",
            "40825      5.0      True  A3BX45SC5SG8BM  B0014F8TIU   \n",
            "45088      3.0      True   AC882JEHSEWW6  B001AV1OVC   \n",
            "45136      3.0      True   AC882JEHSEWW6  B001AV3SS4   \n",
            "48895      5.0      True  A3VGHF7VNFBMCQ  B001IKJOLW   \n",
            "\n",
            "                                                   style   reviewerName  \\\n",
            "3368          {'Size:': ' Large', 'Color:': ' Blue/Red'}             me   \n",
            "12731  {'Size Name:': ' Men's 12-13.5, Women's 14-15....         Papa T   \n",
            "16417  {'Size:': ' 39/40 BR/9-10 M US', 'Color:': ' N...     Tina Diane   \n",
            "17435                                    {'Size:': ' 9'}        Ruth U.   \n",
            "26234                                                NaN         Papa T   \n",
            "33572   {'Size:': ' One Size', 'Color:': ' Black/White'}         Hannah   \n",
            "40825   {'Size:': ' One Size', 'Color:': ' Black/White'}         Hannah   \n",
            "45088                                                NaN           Foxy   \n",
            "45136         {'Size:': ' M/L - 36', 'Color:': ' Black'}           Foxy   \n",
            "48895  {'Size:': ' 7 B(M) US', 'Color:': ' Black/Whit...  sporting road   \n",
            "\n",
            "                                              reviewText  \\\n",
            "3368                                       Happy with it   \n",
            "12731  These best Super Feet. I feel these are as com...   \n",
            "16417                                            Perfect   \n",
            "17435  Love these rings.  Nice to have a choice to ma...   \n",
            "26234  These best Super Feet. I feel these are as com...   \n",
            "33572  Love these! They are nice and snug. My thighs ...   \n",
            "40825  Love these! They are nice and snug. My thighs ...   \n",
            "45088  Do not like the buckle which is too large and ...   \n",
            "45136  Do not like the buckle which is too large and ...   \n",
            "48895                                daughter loves them   \n",
            "\n",
            "                                                 summary   reviewTime  \n",
            "3368                                          Five Stars  07 22, 2016  \n",
            "12731                               What is not to love.   05 1, 2017  \n",
            "16417                                          Love them   07 6, 2017  \n",
            "17435                                         Five Stars  09 23, 2014  \n",
            "26234                               What is not to love.   05 1, 2017  \n",
            "33572                 Love these! They are nice and snug  04 26, 2016  \n",
            "40825                 Love these! They are nice and snug  04 26, 2016  \n",
            "45088  Do not like the buckle which is too large and ...   04 9, 2015  \n",
            "45136  Do not like the buckle which is too large and ...   04 9, 2015  \n",
            "48895                                         Five Stars   02 1, 2018  \n"
          ]
        }
      ],
      "source": [
        "print(filtered_df.head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fdecd0c0",
      "metadata": {
        "id": "fdecd0c0"
      },
      "source": [
        "### So we have reduced dataset size form 828699 rows to 1622 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "274c427b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "274c427b",
        "outputId": "2f7c8ea7-5afb-48ec-e64c-10a59a49960e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1620\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-44afb871e158>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  filtered_df['reviewTime']=pd.to_datetime(filtered_df['reviewTime'])\n"
          ]
        }
      ],
      "source": [
        "# Group reviews by product ASIN\n",
        "filtered_df['reviewTime']=pd.to_datetime(filtered_df['reviewTime'])\n",
        "filtered_df.sort_values('reviewTime')\n",
        "grouped_df = filtered_df.groupby(['asin', 'reviewerID', 'reviewTime'], sort=False)\n",
        "print (len(grouped_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "c2af7173",
      "metadata": {
        "id": "c2af7173"
      },
      "outputs": [],
      "source": [
        "# Initialize a dictionary to store product features as states\n",
        "states= {}\n",
        "products= {}\n",
        "\n",
        "# Iterate over each product\n",
        "for (product_asin, reviewerId, reviewTime), group in grouped_df:\n",
        "    if (product_asin, reviewerId) in states: continue\n",
        "    product = FashionProduct()\n",
        "    product.product_asin = product_asin\n",
        "    product.reviewerId = reviewerId\n",
        "    product.time = reviewTime\n",
        "    if product_asin not in products:\n",
        "        products[product_asin] = product\n",
        "        p= products[product_asin]\n",
        "        p.reviewers = set()\n",
        "        p.sizes = set()\n",
        "        p.colors = set()\n",
        "        p.reviews = set()\n",
        "        p.rating =[]\n",
        "\n",
        "    product.reviewers = products[product_asin].reviewers\n",
        "\n",
        "\n",
        "\n",
        "    # extract size and color metadata from style column\n",
        "    styles=  group[group['style'].notna()]['style']\n",
        "    sizes = styles.apply(lambda x: x.get(\"Size:\", \"\") if \"Size:\" in x else x.get(\"Size Name:\", \"\")).unique().tolist()\n",
        "    colors = styles.apply(lambda x: x.get(\"Color:\", \"\")).unique().tolist()\n",
        "\n",
        "    products[product_asin].sizes.update(sizes)\n",
        "    products[product_asin].colors.update(colors)\n",
        "\n",
        "    #extract other noun metadata from review text\n",
        "    reviews = group[group['reviewText'].notna()]['reviewText']\n",
        "    reviews = \" \".join(reviews.apply(lambda x: \" \".join([extract_nouns(chunk) for chunk in nlp(x).noun_chunks]).strip()).unique())\n",
        "    products[product_asin].reviews.update(reviews)\n",
        "    #using rms instead of average for review ratings to give slightly higher weightage to good reviews\n",
        "    ratings = group[group['overall']>0]['overall'].tolist()\n",
        "    products[product_asin].rating.extend(ratings)\n",
        "    product.ratings = np.sqrt(np.mean( [r**2 for r in products[product_asin].rating]))\n",
        "\n",
        "    sizes = \" \".join(products[product_asin].sizes)\n",
        "    colors = \" \".join(products[product_asin].colors)\n",
        "    reviews = \" \".join(products[product_asin].reviews)\n",
        "    product.metadata= \" \".join((reviews+\" \"+sizes+\" \"+colors).split())\n",
        "\n",
        "    # add past product and reviewer's product metadata\n",
        "    # we will take metatdata of last 2 reviewer only as large metadata causes memory issues\n",
        "    for reviewer in list(product.reviewers)[-2:]:\n",
        "        state = states[(product_asin, reviewer)]\n",
        "        product.metadata += \" \"+state.metadata\n",
        "\n",
        "    # keep past reviewer list\n",
        "    products[product_asin].reviewers.add(reviewerId)\n",
        "\n",
        "    states[(product_asin, reviewerId)] = product\n",
        "\n",
        "states_list= list(states.values())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "8293f163",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8293f163",
        "outputId": "029c70bb-6777-418f-b0b0-165361d9a4a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1618\n"
          ]
        }
      ],
      "source": [
        "states_list.sort(key=lambda x: x.time)\n",
        "print (len(states_list))\n",
        "users={}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "4abe57da",
      "metadata": {
        "id": "4abe57da"
      },
      "outputs": [],
      "source": [
        "for state in states_list:\n",
        "    if state.reviewerId not in users:\n",
        "        users[state.reviewerId] = Reviewer()\n",
        "        users[state.reviewerId].products= set()\n",
        "    for prod1 in list(users[state.reviewerId].products)[-2:]:\n",
        "        state1 = states[(prod1, state.reviewerId)]\n",
        "        state.metadata += state1.metadata\n",
        "    # keep past products list\n",
        "    users[state.reviewerId].products.add(state.product_asin)\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "09fd03e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09fd03e6",
        "outputId": "19643808-3733-4fcc-89d3-dea30cf288ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1584\n"
          ]
        }
      ],
      "source": [
        "#remove states with empty metadata\n",
        "states_list= [s for s in states_list if s.metadata.strip() != '']\n",
        "print(len(states_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "4b2e99e5",
      "metadata": {
        "id": "4b2e99e5"
      },
      "outputs": [],
      "source": [
        "# Create Product Recommendation env\n",
        "class RecommendationEnv(gym.Env):\n",
        "    def __init__(self, states, states_dict, iterations = 10):\n",
        "        self.states = states\n",
        "        self.state = self.states[0]\n",
        "        self.states_dict = states_dict\n",
        "        self.iterations = iterations\n",
        "        self.index = 0\n",
        "        state.action = 0\n",
        "\n",
        "\n",
        "    def step(self, actions):\n",
        "        # Implement the transition logic based on the action\n",
        "        reward= 0\n",
        "        done= False\n",
        "        reviewerId= self.state.reviewerId\n",
        "        future_asins= [p for p in reviewers[reviewerId].products if self.states_dict[(p,reviewerId)].time>self.state.time]\n",
        "        matched_recommendations = False\n",
        "        #predicted recommendations\n",
        "        for i in actions:\n",
        "          if self.states[i].product_asin in future_asins:\n",
        "            self.action = i\n",
        "            matched_recommendations = True\n",
        "            break;\n",
        "\n",
        "\n",
        "        if matched_recommendations:\n",
        "            #Higher reward as they are bought products for the user in future\n",
        "            reward = 1\n",
        "        else:\n",
        "            self.action = actions[0]\n",
        "\n",
        "\n",
        "        self.index += 1\n",
        "        self.state = self.states[self.index]\n",
        "        print(f\"iteration :{self.index}\")\n",
        "        if (self.iterations == self.index): done = True\n",
        "\n",
        "        return self.state, reward, done, {}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def reset(self, iterations = 10):\n",
        "        # Reset the state to the initial position\n",
        "        self.state = self.states[0]\n",
        "        self.iterations = iterations\n",
        "        self.index = 0\n",
        "        return self.state\n",
        "\n",
        "# Create the custom environment\n",
        "env = RecommendationEnv(states_list, states, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "76a005e8",
      "metadata": {
        "id": "76a005e8"
      },
      "outputs": [],
      "source": [
        "# Implementation of DQN algorithm\n",
        "class DQNAgent:\n",
        "    def __init__(self, state_size, action_size, states):\n",
        "        self.states = states\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        # These are hyper parameters for the DQN\n",
        "        self.discount_factor = 0.99\n",
        "        self.learning_rate = 0.001\n",
        "        self.epsilon = 1\n",
        "        self.epsilon_decay = 0.999\n",
        "        self.epsilon_min = 0.01\n",
        "        self.batch_size = 64\n",
        "        self.train_start = 1000\n",
        "        # create replay memory using deque\n",
        "        self.memory = deque(maxlen=2000)\n",
        "\n",
        "        # create main model and target model\n",
        "        self.model = self.build_model()\n",
        "        self.target_model = self.build_model()\n",
        "\n",
        "        # initialize target model\n",
        "        self.update_target_model()\n",
        "\n",
        "    # approximate Q function using Neural Network\n",
        "    # state is input and Q Value of each action is output of network\n",
        "    def build_model(self):\n",
        "        #Using RNN as it is recommended for text classification\n",
        "        # Using the TextVectorization layer to normalize, split, and map strings\n",
        "        # to integers.\n",
        "        encoder = tf.keras.layers.TextVectorization(max_tokens=10000)\n",
        "        metadatas = [product.metadata for product in self.states]\n",
        "        ratings = [product.ratings for product in self.states]\n",
        "        encoder.adapt(metadatas)\n",
        "\n",
        "        model = tf.keras.Sequential([\n",
        "            encoder,\n",
        "            layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
        "            layers.Bidirectional(layers.LSTM(64,  return_sequences=True)),\n",
        "            layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "            layers.Dense(64, activation='relu')\n",
        "        ])\n",
        "        # Create an input layer for ratings\n",
        "        ratings_input = tf.keras.layers.Input(shape=(1,), name='ratings_input')\n",
        "\n",
        "        # Concatenate the output of the previous layers with ratings\n",
        "        concatenated = layers.concatenate([model.output, ratings_input])\n",
        "\n",
        "        # Add additional layers for your desired architecture\n",
        "        dense_layer = layers.Dense(64, activation='relu')(concatenated)\n",
        "         # One Q-value per action\n",
        "        output_layer = layers.Dense(len(self.states), activation='linear')(dense_layer)\n",
        "\n",
        "        # Create the final model with both metadata and ratings as inputs\n",
        "        model = tf.keras.Model(inputs=[model.input, ratings_input], outputs=output_layer)\n",
        "        # Summary of the model\n",
        "        model.summary()\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(loss='mse',\n",
        "                      optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    # after some time interval update the target model to be same with model\n",
        "    def update_target_model(self):\n",
        "        self.target_model.set_weights(self.model.get_weights())\n",
        "\n",
        "    # get recommendations from model using epsilon-greedy policy\n",
        "    def get_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return random.sample(range(self.action_size),10)\n",
        "        else:\n",
        "            q_value = self.model.predict([np.array([state.metadata]), np.array([state.ratings])])\n",
        "            return np.argpartition(q_value[0],-10)[-10:]\n",
        "\n",
        "    # save sample <s,a,r,s'> to the replay memory\n",
        "    def append_sample(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    # pick samples randomly from replay memory (with batch_size)\n",
        "    def train_model(self):\n",
        "        if len(self.memory) < self.train_start:\n",
        "            return\n",
        "        batch_size = min(self.batch_size, len(self.memory))\n",
        "        mini_batch = random.sample(self.memory, batch_size)\n",
        "\n",
        "        update_input_metadata =[]\n",
        "        update_input_ratings =[]\n",
        "        update_target_metadata = []\n",
        "        update_target_ratings = []\n",
        "        action, reward, done = [], [], []\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            update_input_metadata.append(np.array(mini_batch[i][0].metadata))\n",
        "            update_input_ratings.append(np.array(mini_batch[i][0].ratings))\n",
        "            action.append(mini_batch[i][1])\n",
        "            reward.append(mini_batch[i][2])\n",
        "            update_target_metadata.append(np.array(mini_batch[i][3].metadata))\n",
        "            update_target_ratings.append(np.array(mini_batch[i][3].ratings))\n",
        "            done.append(mini_batch[i][4])\n",
        "\n",
        "        target = self.model.predict([np.transpose(update_input_metadata),np.transpose(update_input_ratings)])\n",
        "        target_val = self.target_model.predict([np.transpose(update_target_metadata),np.transpose(update_target_ratings)])\n",
        "\n",
        "        for i in range(self.batch_size):\n",
        "            # Q Learning: get maximum Q value at s' from target model\n",
        "            if done[i]:\n",
        "                target[i][action[i]] = reward[i]\n",
        "            else:\n",
        "                target[i][action[i]] = reward[i] + self.discount_factor * ( np.amax(target_val[i]))\n",
        "\n",
        "        # and do the model fit!\n",
        "        self.model.fit([np.transpose(update_input_metadata),np.transpose(update_input_ratings)], target, batch_size=self.batch_size,\n",
        "                       epochs=1, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "14c99518",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "14c99518",
        "outputId": "9b963c41-0ff0-4b3d-ebd1-6dcdea013579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_vectorization_input (  [(None,)]                    0         []                            \n",
            " InputLayer)                                                                                      \n",
            "                                                                                                  \n",
            " text_vectorization (TextVe  (None, None)                 0         ['text_vectorization_input[0][\n",
            " ctorization)                                                       0]']                          \n",
            "                                                                                                  \n",
            " embedding (Embedding)       (None, None, 64)             35264     ['text_vectorization[0][0]']  \n",
            "                                                                                                  \n",
            " bidirectional (Bidirection  (None, None, 128)            66048     ['embedding[0][0]']           \n",
            " al)                                                                                              \n",
            "                                                                                                  \n",
            " bidirectional_1 (Bidirecti  (None, 64)                   41216     ['bidirectional[0][0]']       \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dense (Dense)               (None, 64)                   4160      ['bidirectional_1[0][0]']     \n",
            "                                                                                                  \n",
            " ratings_input (InputLayer)  [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)   (None, 65)                   0         ['dense[0][0]',               \n",
            "                                                                     'ratings_input[0][0]']       \n",
            "                                                                                                  \n",
            " dense_1 (Dense)             (None, 64)                   4224      ['concatenate[0][0]']         \n",
            "                                                                                                  \n",
            " dense_2 (Dense)             (None, 1589)                 103285    ['dense_1[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 254197 (992.96 KB)\n",
            "Trainable params: 254197 (992.96 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_vectorization_1_input  [(None,)]                    0         []                            \n",
            "  (InputLayer)                                                                                    \n",
            "                                                                                                  \n",
            " text_vectorization_1 (Text  (None, None)                 0         ['text_vectorization_1_input[0\n",
            " Vectorization)                                                     ][0]']                        \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)     (None, None, 64)             35264     ['text_vectorization_1[0][0]']\n",
            "                                                                                                  \n",
            " bidirectional_2 (Bidirecti  (None, None, 128)            66048     ['embedding_1[0][0]']         \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " bidirectional_3 (Bidirecti  (None, 64)                   41216     ['bidirectional_2[0][0]']     \n",
            " onal)                                                                                            \n",
            "                                                                                                  \n",
            " dense_3 (Dense)             (None, 64)                   4160      ['bidirectional_3[0][0]']     \n",
            "                                                                                                  \n",
            " ratings_input (InputLayer)  [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate  (None, 65)                   0         ['dense_3[0][0]',             \n",
            " )                                                                   'ratings_input[0][0]']       \n",
            "                                                                                                  \n",
            " dense_4 (Dense)             (None, 64)                   4224      ['concatenate_1[0][0]']       \n",
            "                                                                                                  \n",
            " dense_5 (Dense)             (None, 1589)                 103285    ['dense_4[0][0]']             \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 254197 (992.96 KB)\n",
            "Trainable params: 254197 (992.96 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "state_size = len(env.states)\n",
        "# Every other product can be a recommendation\n",
        "action_size = state_size\n",
        "agent = DQNAgent(state_size, action_size, env.states)\n",
        "scores, episodes = [], []\n",
        "EPISODES = 25\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cache already rewarded recommendations (optimization done based upon context and to improve the performance to a large extent)\n",
        "next_states = {}\n",
        "done_value = {}\n",
        "action_value = {}\n",
        "for e in range(EPISODES):\n",
        "    done = False\n",
        "    score = 0\n",
        "    state = env.reset(50)\n",
        "\n",
        "    while not done:\n",
        "        if (state.product_asin, state.reviewerId) in next_states:\n",
        "          next_state = next_states[(state.product_asin, state.reviewerId)]\n",
        "          reward = 1\n",
        "          done = done_value[(state.product_asin, state.reviewerId)]\n",
        "          action = action_value[(state.product_asin, state.reviewerId)]\n",
        "          env.index += 1\n",
        "        else:\n",
        "          # get action for the current state and go one step in environment\n",
        "          actions = agent.get_action(state)\n",
        "          next_state, reward, done, info = env.step(actions)\n",
        "          action = env.action\n",
        "          if (reward == 1):\n",
        "            next_states[(state.product_asin, state.reviewerId)]= next_state\n",
        "            done_value[(state.product_asin, state.reviewerId)] = done\n",
        "            action_value[(state.product_asin, state.reviewerId)] = env.action\n",
        "\n",
        "        # save the sample <s, a, r, s'> to the replay memory\n",
        "        agent.append_sample(state, action, reward, next_state, done)\n",
        "        # every time step do the training\n",
        "        agent.train_model()\n",
        "        score += reward\n",
        "        state = next_state\n",
        "\n",
        "        if done:\n",
        "            # every episode update the target model to be same with model\n",
        "            agent.update_target_model()\n",
        "\n",
        "\n",
        "            scores.append(score)\n",
        "            episodes.append(e)\n",
        "            pylab.plot(episodes, scores, 'b')\n",
        "            print(\"episode:\", e, \"  score:\", score, \"  memory length:\",\n",
        "                  len(agent.memory), \"  epsilon:\", agent.epsilon)\n",
        "    if (score > 48): break\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "54Y7Mtx9oCbe",
        "outputId": "928d656d-f19f-4c13-9def-57574bfd9740"
      },
      "id": "54Y7Mtx9oCbe",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iteration :1\n",
            "iteration :2\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "iteration :6\n",
            "iteration :7\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :12\n",
            "iteration :13\n",
            "iteration :14\n",
            "iteration :15\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :19\n",
            "iteration :20\n",
            "iteration :21\n",
            "iteration :22\n",
            "iteration :23\n",
            "iteration :24\n",
            "iteration :25\n",
            "iteration :26\n",
            "iteration :27\n",
            "iteration :28\n",
            "iteration :29\n",
            "iteration :30\n",
            "iteration :31\n",
            "iteration :32\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :35\n",
            "iteration :36\n",
            "iteration :37\n",
            "iteration :38\n",
            "iteration :39\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "iteration :40\n",
            "iteration :41\n",
            "iteration :42\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :46\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :49\n",
            "iteration :50\n",
            "episode: 0   score: 4   memory length: 50   epsilon: 0.9512056281970315\n",
            "iteration :1\n",
            "iteration :2\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "iteration :6\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :13\n",
            "iteration :14\n",
            "iteration :15\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :19\n",
            "iteration :20\n",
            "iteration :21\n",
            "iteration :22\n",
            "iteration :23\n",
            "iteration :24\n",
            "iteration :25\n",
            "iteration :26\n",
            "iteration :27\n",
            "iteration :29\n",
            "iteration :30\n",
            "iteration :31\n",
            "iteration :32\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :35\n",
            "iteration :38\n",
            "iteration :39\n",
            "iteration :40\n",
            "iteration :41\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :46\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :49\n",
            "iteration :50\n",
            "episode: 1   score: 11   memory length: 100   epsilon: 0.9047921471137096\n",
            "iteration :2\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :6\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :13\n",
            "iteration :14\n",
            "iteration :15\n",
            "iteration :16\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :19\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :20\n",
            "iteration :21\n",
            "iteration :22\n",
            "iteration :23\n",
            "iteration :24\n",
            "iteration :25\n",
            "iteration :27\n",
            "iteration :30\n",
            "iteration :32\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :35\n",
            "iteration :39\n",
            "iteration :40\n",
            "iteration :41\n",
            "iteration :42\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :49\n",
            "iteration :50\n",
            "episode: 2   score: 13   memory length: 150   epsilon: 0.8606433826830369\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "iteration :14\n",
            "iteration :15\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :19\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :20\n",
            "iteration :22\n",
            "iteration :23\n",
            "iteration :24\n",
            "iteration :25\n",
            "iteration :27\n",
            "iteration :30\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :32\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :35\n",
            "iteration :39\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :40\n",
            "iteration :41\n",
            "iteration :42\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :49\n",
            "iteration :50\n",
            "episode: 3   score: 17   memory length: 200   epsilon: 0.818648829478636\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "iteration :6\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "iteration :14\n",
            "iteration :15\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :19\n",
            "iteration :20\n",
            "iteration :22\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :25\n",
            "iteration :27\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :35\n",
            "iteration :40\n",
            "iteration :41\n",
            "iteration :42\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :48\n",
            "iteration :50\n",
            "episode: 4   score: 18   memory length: 250   epsilon: 0.7787033741169904\n",
            "iteration :3\n",
            "iteration :4\n",
            "1/1 [==============================] - 0s 90ms/step\n",
            "iteration :5\n",
            "iteration :6\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :13\n",
            "iteration :14\n",
            "iteration :15\n",
            "iteration :16\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "iteration :18\n",
            "iteration :19\n",
            "iteration :20\n",
            "iteration :22\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "iteration :25\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :40\n",
            "iteration :41\n",
            "iteration :42\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :50\n",
            "episode: 5   score: 18   memory length: 300   epsilon: 0.7407070321560997\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :13\n",
            "iteration :14\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :19\n",
            "iteration :20\n",
            "iteration :22\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :25\n",
            "iteration :27\n",
            "iteration :32\n",
            "iteration :33\n",
            "iteration :34\n",
            "iteration :40\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :47\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :50\n",
            "episode: 6   score: 23   memory length: 350   epsilon: 0.704564697832001\n",
            "iteration :3\n",
            "iteration :4\n",
            "iteration :5\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 147ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 204ms/step\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 212ms/step\n",
            "iteration :14\n",
            "iteration :16\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :20\n",
            "iteration :22\n",
            "iteration :24\n",
            "iteration :25\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :34\n",
            "iteration :40\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :50\n",
            "episode: 7   score: 25   memory length: 400   epsilon: 0.6701859060067403\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "iteration :5\n",
            "iteration :6\n",
            "iteration :8\n",
            "iteration :9\n",
            "iteration :10\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "iteration :14\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :18\n",
            "iteration :20\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "iteration :24\n",
            "iteration :25\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :40\n",
            "iteration :42\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :50\n",
            "episode: 8   score: 26   memory length: 450   epsilon: 0.6374846057319378\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :5\n",
            "iteration :6\n",
            "iteration :8\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :14\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :20\n",
            "iteration :22\n",
            "iteration :24\n",
            "iteration :32\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :40\n",
            "iteration :42\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :47\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :50\n",
            "episode: 9   score: 29   memory length: 500   epsilon: 0.6063789448611848\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :8\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "iteration :11\n",
            "iteration :14\n",
            "iteration :16\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :32\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :48\n",
            "iteration :50\n",
            "episode: 10   score: 29   memory length: 550   epsilon: 0.5767910651721362\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :8\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 130ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "iteration :11\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :22\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :34\n",
            "iteration :40\n",
            "iteration :43\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :45\n",
            "iteration :47\n",
            "iteration :48\n",
            "iteration :50\n",
            "episode: 11   score: 30   memory length: 600   epsilon: 0.5486469074854965\n",
            "iteration :3\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "iteration :10\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :22\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :32\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :40\n",
            "iteration :43\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :45\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :48\n",
            "episode: 12   score: 30   memory length: 650   epsilon: 0.5218760262931003\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :5\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "iteration :9\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :18\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :24\n",
            "iteration :32\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :43\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :45\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :48\n",
            "episode: 13   score: 31   memory length: 700   epsilon: 0.4964114134310989\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "iteration :9\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 111ms/step\n",
            "iteration :11\n",
            "iteration :14\n",
            "iteration :16\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :18\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :32\n",
            "iteration :40\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :44\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :47\n",
            "iteration :48\n",
            "episode: 14   score: 31   memory length: 750   epsilon: 0.47218933035690447\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :8\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "iteration :10\n",
            "iteration :11\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :16\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :43\n",
            "iteration :44\n",
            "iteration :45\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :48\n",
            "episode: 15   score: 32   memory length: 800   epsilon: 0.4491491486100748\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "iteration :5\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 205ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "iteration :10\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 226ms/step\n",
            "iteration :14\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :17\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "iteration :22\n",
            "iteration :24\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :48\n",
            "episode: 16   score: 32   memory length: 850   epsilon: 0.427233198057808\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 92ms/step\n",
            "iteration :5\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 209ms/step\n",
            "iteration :9\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 186ms/step\n",
            "iteration :11\n",
            "iteration :14\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :18\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :40\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "iteration :44\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :48\n",
            "episode: 17   score: 33   memory length: 900   epsilon: 0.4063866225452039\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 119ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "iteration :10\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "iteration :14\n",
            "iteration :16\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "iteration :18\n",
            "iteration :22\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :32\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :48\n",
            "episode: 18   score: 33   memory length: 950   epsilon: 0.3865572425889805\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 113ms/step\n",
            "iteration :11\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :17\n",
            "iteration :18\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :48\n",
            "2/2 [==============================] - 1s 427ms/step\n",
            "2/2 [==============================] - 7s 433ms/step\n",
            "1/1 [==============================] - 21s 21s/step - loss: 7.2918e-04\n",
            "episode: 19   score: 33   memory length: 1000   epsilon: 0.3676954247709635\n",
            "2/2 [==============================] - 1s 245ms/step\n",
            "2/2 [==============================] - 1s 246ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 7.4650e-04\n",
            "2/2 [==============================] - 1s 251ms/step\n",
            "2/2 [==============================] - 1s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.6217e-04\n",
            "iteration :3\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 1s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.5427e-04\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 1s 433ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.4421e-04\n",
            "iteration :5\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.1668e-04\n",
            "2/2 [==============================] - 1s 252ms/step\n",
            "2/2 [==============================] - 1s 253ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.9466e-04\n",
            "2/2 [==============================] - 1s 272ms/step\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.0006e-04\n",
            "1/1 [==============================] - 0s 127ms/step\n",
            "iteration :8\n",
            "2/2 [==============================] - 1s 249ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.6757e-04\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "iteration :9\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.3729e-04\n",
            "iteration :10\n",
            "2/2 [==============================] - 1s 240ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.1271e-04\n",
            "iteration :11\n",
            "2/2 [==============================] - 1s 435ms/step\n",
            "2/2 [==============================] - 1s 428ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.7030e-04\n",
            "2/2 [==============================] - 1s 257ms/step\n",
            "2/2 [==============================] - 0s 130ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.1227e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.9322e-04\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "iteration :14\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.8418e-04\n",
            "2/2 [==============================] - 1s 368ms/step\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.5762e-04\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :16\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 1s 244ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.4533e-04\n",
            "iteration :17\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 1s 243ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.4518e-04\n",
            "iteration :18\n",
            "2/2 [==============================] - 1s 351ms/step\n",
            "2/2 [==============================] - 1s 382ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.1253e-04\n",
            "2/2 [==============================] - 1s 240ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.5216e-04\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.6222e-04\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 1s 244ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.6530e-04\n",
            "1/1 [==============================] - 0s 86ms/step\n",
            "iteration :22\n",
            "2/2 [==============================] - 1s 395ms/step\n",
            "2/2 [==============================] - 1s 340ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.0424e-04\n",
            "2/2 [==============================] - 0s 250ms/step\n",
            "2/2 [==============================] - 0s 131ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.7757e-04\n",
            "iteration :24\n",
            "2/2 [==============================] - 1s 258ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.9786e-04\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "2/2 [==============================] - 0s 252ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.5115e-04\n",
            "2/2 [==============================] - 1s 401ms/step\n",
            "2/2 [==============================] - 1s 310ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.4023e-04\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.3302e-04\n",
            "2/2 [==============================] - 1s 238ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.0200e-04\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.6238e-04\n",
            "2/2 [==============================] - 0s 252ms/step\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.1974e-04\n",
            "2/2 [==============================] - 1s 335ms/step\n",
            "2/2 [==============================] - 1s 427ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.5814e-04\n",
            "iteration :32\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 1s 416ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.1034e-04\n",
            "2/2 [==============================] - 1s 242ms/step\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0460e-04\n",
            "2/2 [==============================] - 1s 263ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.5220e-04\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.4640e-04\n",
            "2/2 [==============================] - 1s 421ms/step\n",
            "2/2 [==============================] - 1s 399ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9563e-04\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 1s 261ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3380e-04\n",
            "2/2 [==============================] - 0s 248ms/step\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9406e-04\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9222e-04\n",
            "iteration :40\n",
            "2/2 [==============================] - 1s 308ms/step\n",
            "2/2 [==============================] - 1s 432ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.6477e-04\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7477e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9371e-04\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4462e-04\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "iteration :44\n",
            "2/2 [==============================] - 1s 422ms/step\n",
            "2/2 [==============================] - 1s 425ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2957e-04\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :45\n",
            "2/2 [==============================] - 0s 227ms/step\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1493e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 1s 250ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1117e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 1s 390ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.2362e-04\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :48\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0101e-04\n",
            "2/2 [==============================] - 0s 250ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.2765e-05\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.3161e-05\n",
            "episode: 20   score: 40   memory length: 1050   epsilon: 0.349753957504439\n",
            "2/2 [==============================] - 1s 243ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0010\n",
            "2/2 [==============================] - 1s 396ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.6455e-04\n",
            "iteration :3\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.1218e-04\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.1635e-04\n",
            "iteration :5\n",
            "2/2 [==============================] - 1s 281ms/step\n",
            "2/2 [==============================] - 1s 425ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.8420e-04\n",
            "2/2 [==============================] - 0s 223ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.1383e-04\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.8834e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.0251e-04\n",
            "2/2 [==============================] - 1s 393ms/step\n",
            "2/2 [==============================] - 1s 218ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.5719e-04\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "iteration :10\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.3327e-04\n",
            "1/1 [==============================] - 0s 120ms/step\n",
            "iteration :11\n",
            "2/2 [==============================] - 0s 254ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9268e-04\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.4651e-04\n",
            "2/2 [==============================] - 0s 225ms/step\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.8774e-04\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.1645e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 1s 231ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.8199e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 214ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.9533e-04\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 1s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6858e-04\n",
            "iteration :18\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3256e-04\n",
            "2/2 [==============================] - 0s 252ms/step\n",
            "2/2 [==============================] - 1s 379ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.9720e-04\n",
            "2/2 [==============================] - 0s 248ms/step\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6311e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5986e-04\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "2/2 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9957e-04\n",
            "2/2 [==============================] - 1s 347ms/step\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4488e-04\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :24\n",
            "2/2 [==============================] - 0s 223ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3272e-04\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "2/2 [==============================] - 1s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6335e-04\n",
            "2/2 [==============================] - 1s 307ms/step\n",
            "2/2 [==============================] - 1s 421ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4527e-04\n",
            "2/2 [==============================] - 0s 250ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3355e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 249ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1869e-04\n",
            "2/2 [==============================] - 0s 226ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0997e-04\n",
            "2/2 [==============================] - 1s 420ms/step\n",
            "2/2 [==============================] - 1s 407ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.3254e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.6415e-04\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :32\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 1s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4277e-04\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 0s 123ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4782e-04\n",
            "2/2 [==============================] - 1s 377ms/step\n",
            "2/2 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.6959e-04\n",
            "2/2 [==============================] - 0s 118ms/step\n",
            "2/2 [==============================] - 0s 116ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.8257e-05\n",
            "2/2 [==============================] - 0s 249ms/step\n",
            "2/2 [==============================] - 0s 122ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4121e-04\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 1s 420ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0449e-04\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4550e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1281e-04\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "2/2 [==============================] - 0s 224ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.8001e-05\n",
            "2/2 [==============================] - 1s 411ms/step\n",
            "2/2 [==============================] - 1s 432ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3110e-04\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "2/2 [==============================] - 1s 261ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0344e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 226ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0813e-04\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :44\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.3573e-05\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :45\n",
            "2/2 [==============================] - 1s 385ms/step\n",
            "2/2 [==============================] - 1s 422ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.2121e-04\n",
            "2/2 [==============================] - 0s 132ms/step\n",
            "2/2 [==============================] - 0s 225ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5346e-05\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 1s 266ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.9353e-05\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 1s 396ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 9.8467e-05\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.6823e-05\n",
            "2/2 [==============================] - 1s 248ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.4455e-05\n",
            "episode: 21   score: 46   memory length: 1100   epsilon: 0.33268793286240766\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "2/2 [==============================] - 1s 417ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0027\n",
            "2/2 [==============================] - 0s 248ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0025\n",
            "iteration :3\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0021\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0017\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "iteration :5\n",
            "2/2 [==============================] - 1s 217ms/step\n",
            "2/2 [==============================] - 1s 424ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0012\n",
            "2/2 [==============================] - 1s 419ms/step\n",
            "2/2 [==============================] - 1s 419ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0011\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 1s 242ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.2055e-04\n",
            "2/2 [==============================] - 0s 224ms/step\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.9033e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.9901e-04\n",
            "2/2 [==============================] - 0s 249ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.6960e-04\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 9.6370e-04\n",
            "2/2 [==============================] - 1s 367ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.7598e-04\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.5058e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.4345e-04\n",
            "2/2 [==============================] - 0s 227ms/step\n",
            "2/2 [==============================] - 1s 381ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.2321e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.3564e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1275e-04\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :18\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 1s 273ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.8198e-04\n",
            "2/2 [==============================] - 0s 254ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.7595e-04\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.0475e-04\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.3608e-04\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "2/2 [==============================] - 1s 420ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.2721e-04\n",
            "2/2 [==============================] - 0s 259ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.4113e-04\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 1s 255ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5736e-04\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.5355e-04\n",
            "2/2 [==============================] - 1s 426ms/step\n",
            "2/2 [==============================] - 1s 403ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5659e-04\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 0s 227ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9521e-04\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4901e-04\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 1s 258ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 1.5159e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 253ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9944e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 0s 225ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.4851e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.6271e-04\n",
            "2/2 [==============================] - 1s 285ms/step\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.0030e-04\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2640e-04\n",
            "2/2 [==============================] - 0s 253ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.7197e-04\n",
            "2/2 [==============================] - 1s 395ms/step\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3995e-04\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "2/2 [==============================] - 1s 248ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4066e-04\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7392e-04\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 1s 234ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9536e-04\n",
            "2/2 [==============================] - 1s 463ms/step\n",
            "2/2 [==============================] - 1s 397ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.2551e-05\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.3495e-05\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "2/2 [==============================] - 1s 248ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9917e-04\n",
            "2/2 [==============================] - 1s 354ms/step\n",
            "2/2 [==============================] - 1s 426ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 8.3765e-05\n",
            "2/2 [==============================] - 0s 254ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.6748e-04\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :45\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3530e-04\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 1s 255ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.8725e-04\n",
            "2/2 [==============================] - 1s 399ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3019e-04\n",
            "2/2 [==============================] - 0s 254ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3781e-04\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0586e-04\n",
            "2/2 [==============================] - 1s 421ms/step\n",
            "2/2 [==============================] - 1s 302ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1747e-04\n",
            "episode: 22   score: 47   memory length: 1150   epsilon: 0.31645463417195824\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0025\n",
            "2/2 [==============================] - 0s 243ms/step\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0021\n",
            "iteration :3\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0017\n",
            "2/2 [==============================] - 1s 317ms/step\n",
            "2/2 [==============================] - 0s 256ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0011\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :5\n",
            "2/2 [==============================] - 1s 258ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.5331e-04\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.3847e-04\n",
            "2/2 [==============================] - 1s 268ms/step\n",
            "2/2 [==============================] - 1s 416ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 4.9121e-04\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.0478e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0011\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "2/2 [==============================] - 0s 142ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0012\n",
            "2/2 [==============================] - 1s 294ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0011\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.8958e-04\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "2/2 [==============================] - 1s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.9636e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 1s 300ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.0475e-04\n",
            "2/2 [==============================] - 0s 252ms/step\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.5080e-04\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 231ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5282e-04\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.7714e-04\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :18\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "2/2 [==============================] - 1s 381ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.4191e-04\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.6467e-04\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.2243e-04\n",
            "2/2 [==============================] - 1s 415ms/step\n",
            "2/2 [==============================] - 1s 462ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.0439e-04\n",
            "2/2 [==============================] - 1s 449ms/step\n",
            "2/2 [==============================] - 1s 527ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.2679e-04\n",
            "2/2 [==============================] - 1s 462ms/step\n",
            "2/2 [==============================] - 2s 699ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 3.9664e-04\n",
            "2/2 [==============================] - 1s 399ms/step\n",
            "2/2 [==============================] - 1s 512ms/step\n",
            "1/1 [==============================] - 4s 4s/step - loss: 3.4790e-04\n",
            "2/2 [==============================] - 2s 658ms/step\n",
            "2/2 [==============================] - 1s 428ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.3744e-04\n",
            "2/2 [==============================] - 0s 232ms/step\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.6555e-04\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.9913e-04\n",
            "2/2 [==============================] - 0s 256ms/step\n",
            "2/2 [==============================] - 1s 298ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 5.7280e-04\n",
            "2/2 [==============================] - 0s 133ms/step\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.9577e-05\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 1s 243ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1116e-04\n",
            "2/2 [==============================] - 1s 248ms/step\n",
            "2/2 [==============================] - 0s 248ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3811e-04\n",
            "2/2 [==============================] - 1s 430ms/step\n",
            "2/2 [==============================] - 1s 389ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.3226e-04\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.3814e-04\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 1s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5757e-04\n",
            "2/2 [==============================] - 1s 398ms/step\n",
            "2/2 [==============================] - 1s 389ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0420e-04\n",
            "2/2 [==============================] - 0s 256ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.4873e-05\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.5418e-05\n",
            "2/2 [==============================] - 1s 396ms/step\n",
            "2/2 [==============================] - 1s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.3670e-05\n",
            "2/2 [==============================] - 1s 251ms/step\n",
            "2/2 [==============================] - 1s 651ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.8927e-05\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 0s 254ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 9.0893e-05\n",
            "2/2 [==============================] - 1s 416ms/step\n",
            "2/2 [==============================] - 1s 305ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 9.0988e-05\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5028e-04\n",
            "2/2 [==============================] - 0s 253ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.6344e-05\n",
            "2/2 [==============================] - 0s 253ms/step\n",
            "2/2 [==============================] - 1s 259ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4963e-04\n",
            "2/2 [==============================] - 1s 328ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.3093e-05\n",
            "2/2 [==============================] - 0s 255ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.0599e-05\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.1272e-05\n",
            "2/2 [==============================] - 0s 224ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.0179e-04\n",
            "2/2 [==============================] - 1s 408ms/step\n",
            "2/2 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.9769e-05\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.9171e-04\n",
            "episode: 23   score: 48   memory length: 1200   epsilon: 0.3010134290933992\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 1s 257ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0027\n",
            "2/2 [==============================] - 1s 426ms/step\n",
            "2/2 [==============================] - 0s 244ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0018\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :3\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "2/2 [==============================] - 0s 230ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0014\n",
            "2/2 [==============================] - 1s 244ms/step\n",
            "2/2 [==============================] - 1s 269ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 7.9083e-04\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "iteration :5\n",
            "2/2 [==============================] - 1s 429ms/step\n",
            "2/2 [==============================] - 1s 387ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.4826e-04\n",
            "2/2 [==============================] - 1s 230ms/step\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.8558e-04\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "2/2 [==============================] - 1s 251ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 7.9773e-04\n",
            "2/2 [==============================] - 1s 436ms/step\n",
            "2/2 [==============================] - 1s 442ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 7.1797e-04\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.8632e-04\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 7.9107e-04\n",
            "2/2 [==============================] - 0s 260ms/step\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0010\n",
            "2/2 [==============================] - 1s 352ms/step\n",
            "2/2 [==============================] - 1s 438ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.0444e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 9.4356e-04\n",
            "2/2 [==============================] - 0s 233ms/step\n",
            "2/2 [==============================] - 1s 242ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5560e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1969e-04\n",
            "2/2 [==============================] - 1s 351ms/step\n",
            "2/2 [==============================] - 1s 379ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.5114e-04\n",
            "2/2 [==============================] - 0s 249ms/step\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.0478e-04\n",
            "2/2 [==============================] - 0s 228ms/step\n",
            "2/2 [==============================] - 1s 253ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.4058e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 1s 257ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 4.7343e-04\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 1s 256ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.2617e-04\n",
            "2/2 [==============================] - 1s 248ms/step\n",
            "2/2 [==============================] - 0s 251ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.0822e-04\n",
            "2/2 [==============================] - 0s 257ms/step\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.0575e-04\n",
            "2/2 [==============================] - 1s 363ms/step\n",
            "2/2 [==============================] - 1s 456ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0010\n",
            "2/2 [==============================] - 0s 255ms/step\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1614e-04\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "2/2 [==============================] - 1s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.4773e-04\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "2/2 [==============================] - 1s 256ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 8.8918e-05\n",
            "2/2 [==============================] - 1s 260ms/step\n",
            "2/2 [==============================] - 1s 396ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.9320e-04\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "2/2 [==============================] - 1s 259ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1970e-04\n",
            "2/2 [==============================] - 1s 243ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 4.8358e-04\n",
            "2/2 [==============================] - 0s 258ms/step\n",
            "2/2 [==============================] - 0s 237ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.8901e-04\n",
            "2/2 [==============================] - 1s 421ms/step\n",
            "2/2 [==============================] - 0s 242ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.1746e-04\n",
            "2/2 [==============================] - 0s 234ms/step\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 0.0012\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "2/2 [==============================] - 1s 263ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 5.8172e-04\n",
            "2/2 [==============================] - 0s 260ms/step\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 5.7436e-04\n",
            "2/2 [==============================] - 1s 411ms/step\n",
            "2/2 [==============================] - 1s 336ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.1763e-04\n",
            "2/2 [==============================] - 1s 252ms/step\n",
            "2/2 [==============================] - 0s 235ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0591e-04\n",
            "2/2 [==============================] - 1s 260ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.5183e-04\n",
            "2/2 [==============================] - 1s 428ms/step\n",
            "2/2 [==============================] - 1s 426ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.6258e-04\n",
            "2/2 [==============================] - 0s 241ms/step\n",
            "2/2 [==============================] - 1s 263ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2958e-04\n",
            "2/2 [==============================] - 0s 116ms/step\n",
            "2/2 [==============================] - 1s 260ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.4742e-04\n",
            "2/2 [==============================] - 0s 229ms/step\n",
            "2/2 [==============================] - 0s 236ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 2.8732e-04\n",
            "2/2 [==============================] - 1s 284ms/step\n",
            "2/2 [==============================] - 1s 418ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.4930e-04\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 245ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0571e-04\n",
            "2/2 [==============================] - 0s 257ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.0100e-04\n",
            "2/2 [==============================] - 0s 247ms/step\n",
            "2/2 [==============================] - 1s 339ms/step\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.8475e-04\n",
            "2/2 [==============================] - 1s 244ms/step\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 6.9831e-05\n",
            "2/2 [==============================] - 0s 240ms/step\n",
            "2/2 [==============================] - 0s 250ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 7.4764e-05\n",
            "2/2 [==============================] - 0s 246ms/step\n",
            "2/2 [==============================] - 0s 238ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.2237e-04\n",
            "2/2 [==============================] - 0s 239ms/step\n",
            "2/2 [==============================] - 1s 269ms/step\n",
            "1/1 [==============================] - 3s 3s/step - loss: 6.1497e-04\n",
            "2/2 [==============================] - 1s 417ms/step\n",
            "2/2 [==============================] - 1s 439ms/step\n",
            "1/1 [==============================] - 1s 1s/step - loss: 1.5106e-04\n",
            "episode: 24   score: 49   memory length: 1250   epsilon: 0.28632566791652947\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiQAAAGdCAYAAAAi3mhQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAqdElEQVR4nO3de3RU5aH+8WdyJUBmIFxyEQIR1KgYtFQg9dZKSvDCKYe4aq1t0YO6lECFaFXan6Ln2BMvZ9VWK9qLSzwVtNJKLfZUa1GCLgNSlCpWI1A02JAgaiYkmIvJ/v2xJTsTEsgkk3n3zP5+1po1796TTB52p2se333zWZZlCQAAwKAE0wEAAAAoJAAAwDgKCQAAMI5CAgAAjKOQAAAA4ygkAADAOAoJAAAwjkICAACMSzIdoLuOjg7V1NQoPT1dPp/PdBwAANAHlmXp4MGDysnJUUJC+PMdriskNTU1Gj9+vOkYAACgH/bu3atx48aF/XuuKyTp6emS7H+Q3+83nAYAAPRFQ0ODxo8f3/k9Hi7XFZLDu2n8fj+FBACAGNPfwy04qBUAABhHIQEAAMaFVUhuv/12+Xy+kEd+fn7n683NzSotLdWoUaM0fPhwlZSUqK6uLuKhAQBAfAl7huTUU0/Vvn37Oh+vvPJK52vLli3T+vXrtXbtWlVUVKimpkbz58+PaGAAABB/wj6oNSkpSVlZWUesDwaDeuSRR7RmzRqdf/75kqRHH31UJ598sjZv3qyZM2cOPC0AAIhLYc+Q7Ny5Uzk5OTr++ON1+eWXq7q6WpK0bds2tbW1qaioqPNn8/PzlZubq8rKyl7fr6WlRQ0NDSEPAADgLWEVkhkzZmjVqlV67rnn9NBDD2nPnj0655xzdPDgQdXW1iolJUUjRowI+Z3MzEzV1tb2+p7l5eUKBAKdDy6KBgCA94S1y+aCCy7oHBcUFGjGjBmaMGGCnnrqKaWlpfUrwPLly1VWVta5fPjCKgAAwDsGdNrviBEjdOKJJ2rXrl3KyspSa2ur6uvrQ36mrq6ux2NODktNTe28CBoXQwMAwJsGVEgaGxu1e/duZWdna9q0aUpOTtaGDRs6X6+qqlJ1dbUKCwsHHBQAAMSvsHbZ3HjjjZo7d64mTJigmpoarVixQomJibrssssUCAS0cOFClZWVKSMjQ36/X0uWLFFhYSFn2AAAgKMKq5B8+OGHuuyyy/Txxx9rzJgxOvvss7V582aNGTNGknTfffcpISFBJSUlamlpUXFxsVauXDkowQEAQPzwWZZlmQ7RVUNDgwKBgILBIMeTAAAQQbt3S7/+tTRypHTTTZF974F+f7vubr8AACByWlulZ56RfvlL6a9/tdeNHSstXSqlpBiNFoJCAgBAHHrvPXs2ZNUq6aOP7HU+nzR7tnTNNVKCy26vSyEBACBOtLRITz9tz4Zs3Oisz86WFi60HxMnmkp3dBQSAABi3LvvSr/6lfTYY9LHH9vrfD7pwgulq6+WLrpISnL5N77L4wEAgJ589pn0+9/bsyEvv+ysHzfOngn5j/+QcnPN5QsXhQQAgBjy9tt2CfnNb6RPP7XXJSRIF19sz4bMmeP+2ZCexGBkAAC85cAB6YEH7LNkXn3VWZ+bK111lXTllfbMSCyjkAAA4FJPPSXdeaf01lvOusRE6d/+zT5T5utft5fjAYUEAAAXqa2VbrlF+t3vpKYmZ31SklRaKt18s33WTLyhkAAA4AKrV0s//rH0zjuh68eNkxYvlm64ITaPDemrOP6nAQDgbv/6lz3jsW6ddOiQsz45WSoqku65R5oyxVy+aKKQAAAQRR0d9hky5eVSVVXoa7m50vXXS9//fnzPhvTEY/9cAADMqK62b2j3zDNSc7OzPiVFKi62Z0Py883lM41CAgDAIOnosO8n8z//I+3cGfraxIlSWZl9oKrb7itjAoUEAIAI275duuIK6c03Jcty1qem2pdzv/deadIkU+nciUICAEAEtLdLP/iBfU+ZxsbQ1yZNsl+7+mpmQ3pDIQEAYABee82+d8yOHaHrfT5p6lTp0Uel0083Ei2m0NMAAAhTe7u0ZIk0fLg0Y0ZoGfH7pR/+UGprk954gzLSV8yQAADQR6++at87pvvFy3w+ado06bHHpFNOMZMt1jFDAgDAUbS2StdeKw0dKp11VmgZGTFCuv12ezZk61bKyEAwQwIAQA82bbJvYNf94mUJCdL06fZsyIknmskWj5ghAQDgC9XV0sUXS2lp0nnnhZaRkSPte820t0uVlZSRSGOGBACAL0ydKtXXO8sJCVJhoX2p97w8Y7E8gRkSAAAk7drllJG0NPvqqu3t0iuvUEaigRkSAAAkXXSRM96/3z6lF9HDDAkAwPM+/1x67z17PHo0ZcQECgkAwPOuusoZr1plLIanUUgAAJ63erX9nJQUuusG0UMhAQB42vr19i4bSfre98xm8TIKCQDA0664whk/8oixGJ5HIQEAeFZ9vfTJJ/aYC52ZRSEBAHjWBRc44+efN5cDFBIAgIdt2WI/DxsmTZxoNIrnUUgAAJ50xx2SZdnju+82mwWSz7IO/8/hDg0NDQoEAgoGg/L7/abjAADiVFqa1Nxs36+mvd10mtg30O9vZkgAAJ7z5pt2GZGkoiKzWWCjkAAAPGfuXGf8zDPmcsBBIQEAeMrnn0vV1fY4O1saMsRsHtgoJAAAT/nmN53xU0+Zy4FQFBIAgKf88Y/2c0qKdPbZZrPAQSEBAHjG//6vc0bN4sVmsyAUp/0CADwjEJAaGuyxu779Yh+n/QIA0Ae1tU4ZOf10o1HQAwoJAMATioud8XPPmcuBnlFIAACe8Oab9nMgIGVmms2CI1FIAABxb+lSZ7xypbEYOAoOagUAxL2UFKmtTUpMtC+MhsjjoFYAAI5i0ya7jEjSvHlGo+AoKCQAgLh26aXO+MknzeXA0VFIAABxq7nZPt1XkiZMkJKSzOZB7ygkAIC41fWuvocvGQ93opAAAOLWhg3285AhUkGB2Sw4OgoJACAuPfCAc3n4//f/zGbBsXHaLwAgLg0fLjU1ST6f1NFhOk3847RfAAC62bXLLiOSVFhoNgv6hkICAIg7F13kjJ9/3lwO9B2FBAAQVz7/XHrvPXs8erS96wbuRyEBAMSVq65yxr/5jbkcCA+FBAAQV1avtp+TkqQ5c8xmQd9RSAAAcePZZ52b5y1YYDYLwkMhAQDEja4l5Ne/NpcD4aOQAADiQmOj9Mkn9vjEE81mQfgoJACAuDB7tjPmVN/YM6BCctddd8nn82np0qWd65qbm1VaWqpRo0Zp+PDhKikpUV1d3UBzAgBwVJs328/DhkkTJxqNgn7odyHZunWrfvGLX6ig292Kli1bpvXr12vt2rWqqKhQTU2N5s+fP+CgAAD05o47nPvW3H232Szon34VksbGRl1++eX61a9+pZEjR3auDwaDeuSRR/STn/xE559/vqZNm6ZHH31Ur776qjYfrq4AAETYXXfZzwkJUmmp2Szon34VktLSUl100UUqKioKWb9t2za1tbWFrM/Pz1dubq4qKysHlhQAgB68/LLU3GyPu30tIYYkhfsLTz75pF5//XVt3br1iNdqa2uVkpKiESNGhKzPzMxUbW1tj+/X0tKilpaWzuWGhoZwIwEAPKzrUQHPPGMuBwYmrBmSvXv36vrrr9fq1as1ZMiQiAQoLy9XIBDofIwfPz4i7wsA8IYDB+znoUOlCH01wYCwCsm2bdu0f/9+felLX1JSUpKSkpJUUVGh+++/X0lJScrMzFRra6vq6+tDfq+urk5ZWVk9vufy5csVDAY7H3v37u33PwYA4C0//rEzvv12YzEQAT7LOnxc8rEdPHhQH3zwQci6K6+8Uvn5+br55ps1fvx4jRkzRk888YRKSkokSVVVVcrPz1dlZaVmzpx5zL/R0NCgQCCgYDAov98f5j8HAOAlQ4dKn31mj/v+bYbBMNDv77COIUlPT9eUKVNC1g0bNkyjRo3qXL9w4UKVlZUpIyNDfr9fS5YsUWFhYZ/KCAAAfdXW5pSRsWPNZsHAhX1Q67Hcd999SkhIUElJiVpaWlRcXKyVK1dG+s8AADzuu991xo8/bi4HIiOsXTbRwC4bAEBfJCfbd/b1+aSODtNpMNDvb+5lAwCIOcGgXUYkKT/fbBZEBoUEABBzZs1yxs89Zy4HIodCAgCIOa+/bj8nJEi5uWazIDIoJACAmLJ1q3OKL5eKjx8UEgBATPniMleSpGefNZcDkUUhAQDElMMX9E5Jsc+0QXygkAAAYsZjjznj664zlwORx3VIAAAxIxCQDt8U3l3fXuA6JAAAzzhcRvjv1fhDIQEAxIRly5zxz35mLgcGB7tsAAAxITVVam21x+765oLELhsAgAe0tTllZNw4s1kwOCgkAADXu/hiZ/zHP5rLgcFDIQEAuN5f/2o/+3zSGWeYzYLBQSEBALhadbXU0WGPv/Qls1kweCgkAABXKy52xodnShB/KCQAAFerqrKfk5KkESOMRsEgopAAAFzrhRecU3znzzebBYOLQgIAcK3vfMcZP/64uRwYfBQSAIBr7d9vP6elcWffeEchAQC40r33OuMf/chcDkQHl44HALjSsGHSoUP22F3fVOgJl44HAMSlw2Vk1CizORAdFBIAgOt873vO+LHHzOVA9FBIAACu8+STzviii8zlQPRQSAAArhIM2nf3laTJk81mQfRQSAAArjJnjjN+7jlzORBdFBIAgKts2WI/JyRIkyaZzYLooZAAAFxjxw7nFN9zzjGbBdFFIQEAuMbcuc74//7PXA5EH4UEAOAa779vPycnS0OHGo2CKKOQAABc4be/dcZXXGEsBgyhkAAAXOHaa53xL39pLgfMoJAAAFyhvt5+Tk83GgOGUEgAAMYtX+6M777bXA6Yw91+AQDGpaVJzc322F3fSugr7vYLAIhpbW1OGcnJMZsF5lBIAABGzZ/vjH//e3M5YBaFBABg1J//bD/7fNLMmWazwBwKCQDAmH37pPZ2e3zaaWazwCwKCQDAmNmznfGGDeZywDwKCQDAmLfftp8TE6XRo81mgVkUEgCAES+/7Jzie9FFZrPAPAoJAMCIb37TGf/ud+ZywB2STAcAAAyu+nrp+uvta3z4fJF5z+HDpYQB/idtba39PGSIfXdfeBuFBADiVFmZ9NOfuv/KpzfcYDoB3IBCAgBxpL5emjRJ+uQT00n67s47TSeAG3AMCQDEgUWL7F0oI0ceWUaSk6U//cmeKXHjA5CYIQGAmFVbK+XnS8Fgz69Pny5t2RLdTEB/MUMCADHmiivs2ZDs7CPLSEqK9Ne/2jMPlBHEEmZIACAGvP++VFAgHTzY8+vnnCNt2hTVSEBEMUMCAC522WX2qbp5eUeWkdRU5+JilBHEOmZIACACDh2SjjvOPstlsBUVSS+8MPh/B4gmZkgAYABuvNGewRg2bHDLyJAh9jEhlkUZQXxihgQAwnTokJSV1fvxHJHEmTLwCmZIAKCPFi1yZkN6KiPl5ZG/RgdlBF7BDAkAHMWBA9LEiVJTU8+vZ2VJu3dLQ4dGNRYQd5ghAYAeXHmlPRsyZkzPZeTnP7dnMPbto4wAkcAMCQB84cABKTdX+uyznl/PyZH+9a/oZgK8gkICICY9/LB0++2RmZ1obrZnOnri80m/+IV09dUD/zsAekchARBTRo6MzrU+Jk6U9uwZ/L8DwMYxJABc77bb7JkKn29wy4jPJz3xhH1sCGUEiC5mSAC4UmOjfcxGb9f6SE6WPvlEGj48urkADA5mSAC4yi232DMV6ek9l5HLL7dnMFpbKSNAPAmrkDz00EMqKCiQ3++X3+9XYWGh/vznP3e+3tzcrNLSUo0aNUrDhw9XSUmJ6urqIh4aQHxpbLQvNubzSXfffeTraWl2ObEs6fHHo58PwOALq5CMGzdOd911l7Zt26a//e1vOv/88/WNb3xDb7/9tiRp2bJlWr9+vdauXauKigrV1NRo/vz5gxIcQOz7/ved2ZBDh458ffFiu4QcOsRsCBDvfJZlWQN5g4yMDN1777265JJLNGbMGK1Zs0aXXHKJJOndd9/VySefrMrKSs2cObNP79fQ0KBAIKBgMCi/3z+QaAAiyLLs8jBQjY3S2LG9X+tj6FCpro4CAsSagX5/9/sYkvb2dj355JNqampSYWGhtm3bpra2NhUVFXX+TH5+vnJzc1VZWdnr+7S0tKihoSHkAcAdVq50zm5JSHDGA3mkp/dcRpYts0tPUxNlBPCisM+yeeutt1RYWKjm5mYNHz5c69at0ymnnKLt27crJSVFI0aMCPn5zMxM1dbW9vp+5eXluuOOO8IODmDwZGRIn346+H8nPV2qqaGAAOjHDMlJJ52k7du3a8uWLbruuuu0YMEC/eMf/+h3gOXLlysYDHY+9u7d2+/3AtB/P/mJM4sx2GVk0SJ7NqShgTICwBb2DElKSoomT54sSZo2bZq2bt2qn/3sZ7r00kvV2tqq+vr6kFmSuro6ZWVl9fp+qampSk1NDT85gIjw+3u/1ofPJ+3YIZ1ySnQzAfCeAV+HpKOjQy0tLZo2bZqSk5O1YcOGzteqqqpUXV2twsLCgf4ZABG0YoUzG9JTGSkstGcwOjooIwCiI6wZkuXLl+uCCy5Qbm6uDh48qDVr1mjjxo16/vnnFQgEtHDhQpWVlSkjI0N+v19LlixRYWFhn8+wATC4hg7t/ewWn0+qrpbGjYtuJgCQwiwk+/fv1/e+9z3t27dPgUBABQUFev755/X1r39dknTfffcpISFBJSUlamlpUXFxsVauXDkowQH0zc03S/fc0/vrX/2q9NJLUYsDAD0a8HVIIo3rkMDLZs2SNm6MzPU+Ojrs3S49SUiQPviA2RAAkTPQ729urge4xNF2p0TKxRdL69cP7t8AgP6gkAAuUFg4eGUkMdG+Ky4TjgDcjLv9AoY9+KC0ebOzfOGF9q6WSD0+/5wyAsD9KCSAQfX19g3kDgsEpD/9yVgcADCGQgIYNHJk6HJ9vZEYAGAchQQwpPuZNO463w0AootCAhiQkhK6TBkB4HUUEiDKTj1VamtzlrkoGQBQSICo+s//lLreHPs737GvlAoAXkchAaLk/fftm9odlpkp/eY3xuIAgKtQSIAoyctzxj6fVFtrLgsAuA2FBIiC7mfUdHSYyQEAbkUhAQZZYmLoMmfUAMCRKCTAIJo4MXQ25I03jEUBAFejkACDZNEi6YMPnOVly6TTTzcWBwBcjUICDILt26WHHnKWJ0yQfvITY3EAwPUoJMAgOOMMZ5yYaJ/yCwDoHYUEiLDuZ9R8/rmZHAAQSygkQAQldPt/FGfUAEDfUEiACBk7NrSA7NljLgsAxBoKCRAB3/2u9NFHzvLdd9un/AIA+oZCAgzQxo3S4487ywUF0k03GYsDADEpyXQAIFZ9+qmUkRG6LiVF+vvfzeQBgFjGDAkQprPOss+k6V5GJKmlJfp5ACAeMEMC9EFPsyFdJSVJra3RywMA8YYZEuAovvzl3mdDJPtgVsuS2tqOvP4IAKDvmCEBuvnnP6VJk3p/PSnJLiAAgMhhhgT4wpQp9ixHb2WktNSZDQEARBYzJPC0Y82GJCdzbAgARAMzJPCkCy88+mzIDTfYsyGUEQCIDmZI4DnJyT3f8C41VWpujn4eAAAzJPAYn+/IMnLnnfZsCGUEAMyhkMAT/vKXI0/LPe88u4j86EdmMgEAHOyyQdybNk16/fXQdVu2SNOnm8kDADgShQRxLSlJam8PXWdZZrIAAHrHLhvELZ8vtIwMGUIZAQC3opAg7qxadeTxIvPmSZ99ZiINAKAv2GWDuHLSSdJ774Wu27lTmjzZTB4AQN9QSBA3erq5HbtoACA2sMsGcaF7GRk2jDICALGEQoKY9vOfH1lGvvtdqbHRTB4AQP+wywYxa8IEqbo6dN3HH0sZGWbyAAD6j0KCmMTxIgAQX9hlg5jyySdHlpERIygjABDrKCSIGQ89JI0aFbru+9+XPv3UTB4AQOSwywYxY9Gi0GWOFwGA+EEhQUyYPTt0mV00ABBf2GWDmPDCC864qspcDgDA4KCQwPW6z46ceKKZHACAwUMhgesxOwIA8Y9CAlf72tdCl5kdAYD4RCGBq23c6IyZHQGA+EUhgWt95Suhy8yOAED8opDAtSornTGzIwAQ3ygkcKXp00OXmR0BgPhGIYErbd3qjA8cMJcDABAdFBK4zhlnhC53v38NACD+UEjgOtu3O2NmRwDAGygkcJWCgtBlZkcAwBsoJHCVt95yxsyOAIB3UEjgGqeeGrrM7AgAeAeFBK7xj384Y2ZHAMBbKCRwhZNOCl1mdgQAvIVCAld47z1nzOwIAHhPWIWkvLxcZ555ptLT0zV27FjNmzdPVd2u6d3c3KzS0lKNGjVKw4cPV0lJierq6iIaGvFl0qTQZWZHAMB7wiokFRUVKi0t1ebNm/XCCy+ora1Ns2fPVlNTU+fPLFu2TOvXr9fatWtVUVGhmpoazZ8/P+LBET/++U9nzOwIAHiTz7Isq7+//NFHH2ns2LGqqKjQueeeq2AwqDFjxmjNmjW65JJLJEnvvvuuTj75ZFVWVmrmzJnHfM+GhgYFAgEFg0H5/f7+RkOMyMuT3n/fWe7/pxEAYNJAv78HdAxJMBiUJGVkZEiStm3bpra2NhUVFXX+TH5+vnJzc1XZ9datXbS0tKihoSHkAe/oWkaYHQEA7+p3Ieno6NDSpUt11llnacqUKZKk2tpapaSkaMSIESE/m5mZqdra2h7fp7y8XIFAoPMxfvz4/kZCjMnNDV3m2BEA8K5+F5LS0lLt2LFDTz755IACLF++XMFgsPOxd+/eAb0fYkfX/6mZHQEAb0vqzy8tXrxYzz77rDZt2qRx48Z1rs/KylJra6vq6+tDZknq6uqUlZXV43ulpqYqNTW1PzEQw447LnSZ2REA8LawZkgsy9LixYu1bt06vfjii8rLywt5fdq0aUpOTtaGDRs611VVVam6ulqFhYWRSYy4UFPjjJkdAQCENUNSWlqqNWvW6JlnnlF6enrncSGBQEBpaWkKBAJauHChysrKlJGRIb/fryVLlqiwsLBPZ9jAG7KzQ5eZHQEAhHXar8/n63H9o48+qiuuuEKSfWG0G264QU888YRaWlpUXFyslStX9rrLpjtO+41/XT9GnOYLAPFhoN/fA7oOyWCgkMS3zExp/35n2V2fPgBAfxm9DgkQLsoIAKAnFBJEDceKAAB6QyFB1HzyiTNmdgQA0BWFBFExcqTpBAAAN6OQICrq650xsyMAgO4oJBh03W5tBADAEfp16XjEvwcekP7rv6RIXNX/i5tCS2J2BADQMwoJQiQmSh0dplMAALyGXTbQtdfaV0/1+Qa3jDA7AgDoDTMkHpaQcPSSsGOHdOqp0csDAPAuZkg85tJLndmQnsrIccfZ6y2LMgIAiB5mSDyil/sidnr7bemUU6KTBQCA7pghiWNz5jizIT3Jy3NmQygjAACTmCGJI5YlHTggjR179J/bv18aMyY6mQAA6AsKSRxJOMp8V36+9M470csCAEA4KCRxIjOz5/XMhgAAYgHHkMSJ/fud8emnO8eGUEYAALGAQhIHuh+0+sYbZnIAANBfFJIYN39+6DJXQwUAxCIKSYxbt84Zf/vb5nIAADAQFJIY1n1XzerVZnIAADBQFJIY9fTTocvsqgEAxDIKSYwqKXHGWVnmcgAAEAkUkhjk94cu79tnJgcAAJFCIYkx+/dLBw86y2+9ZS4LAACRQiGJMV2vyJqYKE2ZYi4LAACRQiGJIeeeG7r8+edmcgAAEGkUkhjy8svO+OabzeUAACDSKCQxovs1R+66y0wOAAAGA4UkBjzySOgy1xwBAMQbCkkMuOoqZzx5srkcAAAMFgqJy6Wmhi7v3GkmBwAAg4lC4mL790utrc5yXZ25LAAADCYKiYt1veZIUpI0dqy5LAAADCYKiUudckroclubmRwAAEQDhcSl3nnHGd93n7kcAABEA4XEhbpfc2TpUiMxAACIGgqJy9xyS+gy1xwBAHgBhcRl7r7bGc+YYS4HAADRRCFxkaSk0OXNm83kAAAg2igkLrFjh9Te7ixzzREAgJdQSFzitNOccVoa1xwBAHgLhcQFxo0LXT50yEwOAABMoZC4wL/+5Yx//3tzOQAAMIVCYlj3a47Mn28mBwAAJlFIDHnzzSPLCNccAQB4FYXEgK98RZo6NXTdvfeayQIAgBskHftHEEmJiVJHR+g6ZkYAAF5HIYmi7rtoJMoIAAASu2yi4oUXjiwj48ZRRgAAOIxCMshOP12aPTt03cMPS3v3GokDAIArsctmELGLBgCAvmGGZJBQRgAA6DsKSYStXXtkGTnhBMoIAABHwy6bCDr+eGnPntB1f/mL9PWvm8kDAECsoJBECLtoAADoP3bZRABlBACAgaGQDMAvfnFkGZk2jTICAEC42GXTT1lZUl1d6Lq//10qKDCTBwCAWEYh6Ydhw6RDh0LXMSsCAED/scumH7qWkYQEyggAAANFIQnT9u2hy+3tRmIAABBXKCRhOuMMZ3z99eZyAAAQTygkA/DTn5pOAABAfAi7kGzatElz585VTk6OfD6f/vCHP4S8blmWbrvtNmVnZystLU1FRUXauXNnpPIadfXVphMAABCfwi4kTU1Nmjp1qh588MEeX7/nnnt0//336+GHH9aWLVs0bNgwFRcXq7m5ecBhTfv1r53xG2+YywEAQLzxWVb/zxHx+Xxat26d5s2bJ8meHcnJydENN9ygG2+8UZIUDAaVmZmpVatW6Vvf+tYx37OhoUGBQEDBYFB+v7+/0QZF14ugcWYNAACOgX5/R/QYkj179qi2tlZFRUWd6wKBgGbMmKHKysoef6elpUUNDQ0hDzeaMMF0AgAA4ldEC0ltba0kKTMzM2R9ZmZm52vdlZeXKxAIdD7Gjx8fyUgRU13tjJkdAQAgsoyfZbN8+XIFg8HOx969e01HAgAAURbRQpKVlSVJqut2k5e6urrO17pLTU2V3+8PebhNSoozDgTM5QAAIF5FtJDk5eUpKytLGzZs6FzX0NCgLVu2qLCwMJJ/Kqra2pxxfb2xGAAAxK2wb67X2NioXbt2dS7v2bNH27dvV0ZGhnJzc7V06VLdeeedOuGEE5SXl6dbb71VOTk5nWfixJpeDn0BAAARFHYh+dvf/qavfe1rnctlZWWSpAULFmjVqlW66aab1NTUpGuuuUb19fU6++yz9dxzz2nIkCGRSx1F2dnO+OyzzeUAACCeDeg6JIPBbdch4dojAAAcm6uuQxJvVq40nQAAAG+gkBxFaakz7uVK+QAAIAIoJH20aJHpBAAAxC8KSS9mzTKdAAAA76CQ9OLFF53xvn3mcgAA4AUUkj7o5SKzAAAgQigkPcjIcMZJYV+pBQAAhItC0oNPP3XGXS8bDwAABgeFBAAAGEch6SahyxbJzTWXAwAAL6GQdNP18vAffGAuBwAAXkIh6WL7dtMJAADwJgpJF2ec4YyvuspcDgAAvIZC0otf/cp0AgAAvINC8oUf/ch0AgAAvItC8oX//m9n/Nxz5nIAAOBFFJIeFBebTgAAgLdQSCSddprpBAAAeBuFRNKOHc6463VIAABAdFBIAACAcZ4vJEOGOONhw8zlAADAyzxfSFpanHFjo7kcAAB4macLSW2t6QQAAEDyeCHJznbGZ55pLgcAAF7n6ULS1WuvmU4AAIB3ebaQ/PnPphMAAIDDPFtILrzQGZeXm8sBAAA8XEi6uuUW0wkAAPA2TxaSkhLTCQAAQFeeLCRPP+2M9+0zlwMAANg8WUi6ysoynQAAAHiukIwd64wTPPevBwDAnTz3lfzRR864vd1cDgAA4PBcIQEAAO7jqUKSmOiMu142HgAAmOWpQtLR4YxraszlAAAAoTxTSLizLwAA7uWZQtJ1F823v20uBwAAOJJnCslxxznj1avN5QAAAEdKMh0gWj780HQCAADQG8/MkAAAAPeikAAAAOMoJAAAwDgKCQAAMI5CAgAAjKOQAAAA4ygkAADAOAoJAAAwjkICAACMo5AAAADjKCQAAMA4CgkAADCOQgIAAIxz3d1+LcuSJDU0NBhOAgAA+urw9/bh7/Fwua6QHDx4UJI0fvx4w0kAAEC4Dh48qEAgEPbv+az+VplB0tHRoZqaGqWnp8vn80X0vRsaGjR+/Hjt3btXfr8/ou+N3rHdzWC7m8F2N4PtbkbX7Z6enq6DBw8qJydHCQnhHxHiuhmShIQEjRs3blD/ht/v5wNrANvdDLa7GWx3M9juZhze7v2ZGTmMg1oBAIBxFBIAAGCcpwpJamqqVqxYodTUVNNRPIXtbgbb3Qy2uxlsdzMiud1dd1ArAADwHk/NkAAAAHeikAAAAOMoJAAAwDgKCQAAMM4zheTBBx/UxIkTNWTIEM2YMUOvvfaa6Uhx7/bbb5fP5wt55Ofnm44VdzZt2qS5c+cqJydHPp9Pf/jDH0JetyxLt912m7Kzs5WWlqaioiLt3LnTTNg4caxtfsUVVxzx2Z8zZ46ZsHGkvLxcZ555ptLT0zV27FjNmzdPVVVVIT/T3Nys0tJSjRo1SsOHD1dJSYnq6uoMJY4PfdnuX/3qV4/4zF977bVh/R1PFJLf/va3Kisr04oVK/T6669r6tSpKi4u1v79+01Hi3unnnqq9u3b1/l45ZVXTEeKO01NTZo6daoefPDBHl+/5557dP/99+vhhx/Wli1bNGzYMBUXF6u5uTnKSePHsba5JM2ZMyfks//EE09EMWF8qqioUGlpqTZv3qwXXnhBbW1tmj17tpqamjp/ZtmyZVq/fr3Wrl2riooK1dTUaP78+QZTx76+bHdJuvrqq0M+8/fcc094f8jygOnTp1ulpaWdy+3t7VZOTo5VXl5uMFX8W7FihTV16lTTMTxFkrVu3brO5Y6ODisrK8u69957O9fV19dbqamp1hNPPGEgYfzpvs0ty7IWLFhgfeMb3zCSx0v2799vSbIqKiosy7I/28nJydbatWs7f+add96xJFmVlZWmYsad7tvdsizrvPPOs66//voBvW/cz5C0trZq27ZtKioq6lyXkJCgoqIiVVZWGkzmDTt37lROTo6OP/54XX755aqurjYdyVP27Nmj2trakM9/IBDQjBkz+PwPso0bN2rs2LE66aSTdN111+njjz82HSnuBINBSVJGRoYkadu2bWprawv5vOfn5ys3N5fPewR13+6HrV69WqNHj9aUKVO0fPlyHTp0KKz3dd3N9SLtwIEDam9vV2ZmZsj6zMxMvfvuu4ZSecOMGTO0atUqnXTSSdq3b5/uuOMOnXPOOdqxY4fS09NNx/OE2tpaSerx83/4NUTenDlzNH/+fOXl5Wn37t364Q9/qAsuuECVlZVKTEw0HS8udHR0aOnSpTrrrLM0ZcoUSfbnPSUlRSNGjAj5WT7vkdPTdpekb3/725owYYJycnL05ptv6uabb1ZVVZWefvrpPr933BcSmHPBBRd0jgsKCjRjxgxNmDBBTz31lBYuXGgwGTC4vvWtb3WOTzvtNBUUFGjSpEnauHGjZs2aZTBZ/CgtLdWOHTs4Li3Ketvu11xzTef4tNNOU3Z2tmbNmqXdu3dr0qRJfXrvuN9lM3r0aCUmJh5xlHVdXZ2ysrIMpfKmESNG6MQTT9SuXbtMR/GMw59xPv9mHX/88Ro9ejSf/QhZvHixnn32Wb300ksaN25c5/qsrCy1traqvr4+5Of5vEdGb9u9JzNmzJCksD7zcV9IUlJSNG3aNG3YsKFzXUdHhzZs2KDCwkKDybynsbFRu3fvVnZ2tukonpGXl6esrKyQz39DQ4O2bNnC5z+KPvzwQ3388cd89gfIsiwtXrxY69at04svvqi8vLyQ16dNm6bk5OSQz3tVVZWqq6v5vA/AsbZ7T7Zv3y5JYX3mPbHLpqysTAsWLNCXv/xlTZ8+XT/96U/V1NSkK6+80nS0uHbjjTdq7ty5mjBhgmpqarRixQolJibqsssuMx0trjQ2Nob8V8iePXu0fft2ZWRkKDc3V0uXLtWdd96pE044QXl5ebr11luVk5OjefPmmQsd4462zTMyMnTHHXeopKREWVlZ2r17t2666SZNnjxZxcXFBlPHvtLSUq1Zs0bPPPOM0tPTO48LCQQCSktLUyAQ0MKFC1VWVqaMjAz5/X4tWbJEhYWFmjlzpuH0setY23337t1as2aNLrzwQo0aNUpvvvmmli1bpnPPPVcFBQV9/0MDOkcnhjzwwANWbm6ulZKSYk2fPt3avHmz6Uhx79JLL7Wys7OtlJQU67jjjrMuvfRSa9euXaZjxZ2XXnrJknTEY8GCBZZl2af+3nrrrVZmZqaVmppqzZo1y6qqqjIbOsYdbZsfOnTImj17tjVmzBgrOTnZmjBhgnX11VdbtbW1pmPHvJ62uSTr0Ucf7fyZzz77zFq0aJE1cuRIa+jQoda///u/W/v27TMXOg4ca7tXV1db5557rpWRkWGlpqZakydPtn7wgx9YwWAwrL/j++KPAQAAGBP3x5AAAAD3o5AAAADjKCQAAMA4CgkAADCOQgIAAIyjkAAAAOMoJAAAwDgKCQAAMI5CAgAAjKOQAAAA4ygkAADAOAoJAAAw7v8DWYYU4yPzXloAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "agent.model.save('Reco_DQN.keras')"
      ],
      "metadata": {
        "id": "KHcV2nad047g"
      },
      "id": "KHcV2nad047g",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "9dd1ea33",
      "metadata": {
        "id": "9dd1ea33"
      },
      "outputs": [],
      "source": [
        "\n",
        "#Deep REINFORCE Implementation\n",
        "class REINFORCEAgent:\n",
        "    def __init__(self, state_size, action_size, states):\n",
        "        self.states = states\n",
        "        # get size of state and action\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "\n",
        "        # These are hyper parameters for the Policy Gradient\n",
        "        self.discount_factor = 0.99\n",
        "        self.learning_rate = 0.001\n",
        "        self.hidden1, self.hidden2 = 24, 24\n",
        "\n",
        "        # create model for policy network\n",
        "        self.model = self.build_model()\n",
        "\n",
        "        # lists for the states, actions and rewards\n",
        "        self.states, self.actions, self.rewards = [], [], []\n",
        "\n",
        "    # approximate policy using Neural Network\n",
        "    # state is input and probability of each action is output of network\n",
        "    def build_model(self):\n",
        "        #Using RNN as it is recommended for text classification\n",
        "        # Using the TextVectorization layer to normalize, split, and map strings\n",
        "        # to integers.\n",
        "        encoder = tf.keras.layers.TextVectorization(max_tokens=10000)\n",
        "        metadatas = [product.metadata for product in self.states]\n",
        "        ratings = [product.ratings for product in self.states]\n",
        "        encoder.adapt(metadatas)\n",
        "\n",
        "        model = tf.keras.Sequential([\n",
        "            encoder,\n",
        "            layers.Embedding(len(encoder.get_vocabulary()), 64, mask_zero=True),\n",
        "            layers.Bidirectional(layers.LSTM(64,  return_sequences=True)),\n",
        "            layers.Bidirectional(tf.keras.layers.LSTM(32)),\n",
        "            layers.Dense(64, activation='relu')\n",
        "        ])\n",
        "        # Create an input layer for ratings\n",
        "        ratings_input = tf.keras.layers.Input(shape=(1,), name='ratings_input')\n",
        "\n",
        "        # Concatenate the output of the previous layers with ratings\n",
        "        concatenated = layers.concatenate([model.output, ratings_input])\n",
        "\n",
        "        # Add additional layers for your desired architecture\n",
        "        dense_layer = layers.Dense(64, activation='relu')(concatenated)\n",
        "         # One Q-value per action\n",
        "        output_layer = layers.Dense(len(self.states), activation='softmax')(dense_layer)\n",
        "        # Create the final model with both metadata and ratings as inputs\n",
        "        model = tf.keras.Model(inputs=[model.input, ratings_input], outputs=output_layer)\n",
        "        # Summary of the model\n",
        "        model.summary()\n",
        "\n",
        "        # Compile the model\n",
        "        model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate=self.learning_rate))\n",
        "        return model\n",
        "\n",
        "    # using the output of policy network, pick action stochastically\n",
        "    def get_actions(self, state):\n",
        "        policy = self.model.predict([np.array([state.metadata]), np.array([state.ratings])], batch_size=1).flatten()\n",
        "        return np.random.choice(self.action_size, 10, p=policy)\n",
        "\n",
        "    # In Policy Gradient, Q function is not available.\n",
        "    # Instead agent uses sample returns for evaluating policy\n",
        "    def discount_rewards(self, rewards):\n",
        "        discounted_rewards = np.zeros_like(rewards, dtype=float)\n",
        "        running_add = 0\n",
        "        for t in reversed(range(0, len(rewards))):\n",
        "            running_add = running_add * self.discount_factor + rewards[t]\n",
        "            discounted_rewards[t] = running_add\n",
        "        return discounted_rewards\n",
        "\n",
        "    # save <s, a ,r> of each step\n",
        "    def append_sample(self, state, action, reward):\n",
        "        self.states.append(state)\n",
        "        self.rewards.append(reward)\n",
        "        self.actions.append(action)\n",
        "\n",
        "    # update policy network every episode\n",
        "    def train_model(self):\n",
        "        episode_length = len(self.states)\n",
        "\n",
        "        discounted_rewards = self.discount_rewards(self.rewards)\n",
        "        discounted_rewards -= np.mean(discounted_rewards)\n",
        "        discounted_rewards /= np.std(discounted_rewards)\n",
        "\n",
        "        update_input_metadata = []\n",
        "        update_input_ratings = []\n",
        "        advantages = np.zeros((episode_length, self.action_size))\n",
        "\n",
        "        for i in range(episode_length):\n",
        "            update_input_metadata.append(self.states[i].metadata)\n",
        "            update_input_ratings.append(self.states[i].ratings)\n",
        "            advantages[i][self.actions[i]] = discounted_rewards[i]\n",
        "\n",
        "        self.model.fit([np.transpose(update_input_metadata),np.transpose(update_input_ratings)], advantages, epochs=1, verbose=0)\n",
        "        self.states, self.actions, self.rewards = [], [], []\n",
        "\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the custom environment\n",
        "env = RecommendationEnv(states_list, states, 10)\n",
        "state_size = len(env.states)\n",
        "# Every other product can be a recommendation\n",
        "action_size = state_size\n",
        "scores, episodes = [], []\n",
        "EPISODES = 25\n",
        "# make REINFORCE agent\n",
        "agent = REINFORCEAgent(state_size, action_size, env.states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EEbIq4phxcgG",
        "outputId": "5dbe1dbe-9fde-4b67-bc65-e5f108be1405"
      },
      "id": "EEbIq4phxcgG",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " text_vectorization_10_inpu  [(None,)]                    0         []                            \n",
            " t (InputLayer)                                                                                   \n",
            "                                                                                                  \n",
            " text_vectorization_10 (Tex  (None, None)                 0         ['text_vectorization_10_input[\n",
            " tVectorization)                                                    0][0]']                       \n",
            "                                                                                                  \n",
            " embedding_10 (Embedding)    (None, None, 64)             35520     ['text_vectorization_10[0][0]'\n",
            "                                                                    ]                             \n",
            "                                                                                                  \n",
            " bidirectional_20 (Bidirect  (None, None, 128)            66048     ['embedding_10[0][0]']        \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " bidirectional_21 (Bidirect  (None, 64)                   41216     ['bidirectional_20[0][0]']    \n",
            " ional)                                                                                           \n",
            "                                                                                                  \n",
            " dense_30 (Dense)            (None, 64)                   4160      ['bidirectional_21[0][0]']    \n",
            "                                                                                                  \n",
            " ratings_input (InputLayer)  [(None, 1)]                  0         []                            \n",
            "                                                                                                  \n",
            " concatenate_10 (Concatenat  (None, 65)                   0         ['dense_30[0][0]',            \n",
            " e)                                                                  'ratings_input[0][0]']       \n",
            "                                                                                                  \n",
            " dense_31 (Dense)            (None, 64)                   4224      ['concatenate_10[0][0]']      \n",
            "                                                                                                  \n",
            " dense_32 (Dense)            (None, 1584)                 102960    ['dense_31[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 254128 (992.69 KB)\n",
            "Trainable params: 254128 (992.69 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "84cb716c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "84cb716c",
        "outputId": "94c92351-5bcc-4b03-c683-903cb2ec5844"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 5s 5s/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :4\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "iteration :5\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 64ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 136ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :19\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :25\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :28\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :30\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "iteration :31\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :32\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :33\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "iteration :35\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :36\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "iteration :37\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "iteration :39\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 81ms/step\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :49\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :50\n",
            "episode: 0   score: 7\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "iteration :4\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :8\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 110ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :25\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "iteration :28\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "iteration :33\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :35\n",
            "1/1 [==============================] - 0s 82ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :39\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :45\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :49\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :50\n",
            "episode: 1   score: 11\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 114ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :25\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :28\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :33\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "iteration :39\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 179ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :49\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "iteration :50\n",
            "episode: 2   score: 13\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :13\n",
            "1/1 [==============================] - 0s 230ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 80ms/step\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "iteration :28\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "iteration :33\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :49\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :50\n",
            "episode: 3   score: 14\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 117ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 122ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 182ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 183ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 174ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 210ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :18\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "iteration :22\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :28\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :33\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 75ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "iteration :43\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :49\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :50\n",
            "episode: 4   score: 20\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 115ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 131ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :27\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 76ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :50\n",
            "episode: 5   score: 21\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 194ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 214ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 266ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 129ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :26\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :50\n",
            "episode: 6   score: 22\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 139ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 173ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :50\n",
            "episode: 7   score: 22\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 47ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 79ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 102ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 124ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "iteration :50\n",
            "episode: 8   score: 22\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 77ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 96ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 99ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 133ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 237ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "iteration :29\n",
            "1/1 [==============================] - 0s 87ms/step\n",
            "iteration :34\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "iteration :40\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 167ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :50\n",
            "episode: 9   score: 25\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 78ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 101ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 105ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 156ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :41\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :50\n",
            "episode: 10   score: 26\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "iteration :2\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 97ms/step\n",
            "iteration :10\n",
            "1/1 [==============================] - 0s 94ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 138ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :15\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :21\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 123ms/step\n",
            "iteration :38\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 61ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 175ms/step\n",
            "iteration :46\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "iteration :47\n",
            "1/1 [==============================] - 0s 66ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :50\n",
            "episode: 11   score: 33\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "iteration :3\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 98ms/step\n",
            "iteration :11\n",
            "1/1 [==============================] - 0s 93ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 154ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 74ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :50\n",
            "episode: 12   score: 35\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 134ms/step\n",
            "iteration :14\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :23\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "iteration :48\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :50\n",
            "episode: 13   score: 38\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 63ms/step\n",
            "iteration :7\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 116ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 70ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 43ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :48\n",
            "episode: 14   score: 39\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :1\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "iteration :9\n",
            "1/1 [==============================] - 0s 106ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :42\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "iteration :48\n",
            "episode: 15   score: 42\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 71ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :44\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :48\n",
            "episode: 16   score: 43\n",
            "1/1 [==============================] - 0s 55ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 103ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "iteration :24\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :48\n",
            "episode: 17   score: 44\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "iteration :6\n",
            "1/1 [==============================] - 0s 108ms/step\n",
            "iteration :12\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "iteration :17\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "iteration :24\n",
            "episode: 18   score: 47\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "iteration :16\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "iteration :20\n",
            "1/1 [==============================] - 0s 72ms/step\n",
            "iteration :24\n",
            "episode: 19   score: 49\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# run algorithm\n",
        "scores, episodes = [], []\n",
        "#cache already rewarded recommendations\n",
        "next_states = {}\n",
        "done_value = {}\n",
        "action_value = {}\n",
        "for e in range(EPISODES):\n",
        "  done = False\n",
        "  score = 0\n",
        "  state = env.reset(50)\n",
        "\n",
        "  while not done:\n",
        "      if (state.product_asin, state.reviewerId) in next_states:\n",
        "          next_state = next_states[(state.product_asin, state.reviewerId)]\n",
        "          reward = 1\n",
        "          done = done_value[(state.product_asin, state.reviewerId)]\n",
        "          action = action_value[(state.product_asin, state.reviewerId)]\n",
        "          env.index += 1\n",
        "      else:\n",
        "          # get action for the current state and go one step in environment\n",
        "          actions = agent.get_actions(state)\n",
        "          next_state, reward, done, info = env.step(actions)\n",
        "          action= env.action\n",
        "          if (reward == 1):\n",
        "            next_states[(state.product_asin, state.reviewerId)]= next_state\n",
        "            done_value[(state.product_asin, state.reviewerId)] = done\n",
        "            action_value[(state.product_asin, state.reviewerId)] = env.action\n",
        "      # save the sample <s, a, r> to the memory\n",
        "      agent.append_sample(state, action, reward)\n",
        "\n",
        "      score += reward\n",
        "      state = next_state\n",
        "\n",
        "      if done:\n",
        "          # every episode, agent learns from sample returns\n",
        "          agent.train_model()\n",
        "          scores.append(score)\n",
        "          episodes.append(e)\n",
        "          pylab.plot(episodes, scores, 'b')\n",
        "          print(\"episode:\", e, \"  score:\", score)\n",
        "\n",
        "  if (score > 48): break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Your formal method to compare the results of deliverables 4 and 5. This will be evaluated\n",
        "for 2 Marks. Choice of appropriate measures, and your comments\n",
        "on the result counts.\n"
      ],
      "metadata": {
        "id": "GCjR4tiFvebX"
      },
      "id": "GCjR4tiFvebX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both DQN and Deep REINFORCED performed well and converged in very less episode by adding the optimization code which I added, however Deep REINFORCE performed better, it converged very fast within a minute and 19 episodes with 49/50 correct recommendation. DQN converged in 3 minutes and 25 episodes with 49/50 scores. Both recommended correct next buys for 49 products out of 50 products which we tested with a limit of 25 episodes."
      ],
      "metadata": {
        "id": "c6Sdiy2uv0mt"
      },
      "id": "c6Sdiy2uv0mt"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}